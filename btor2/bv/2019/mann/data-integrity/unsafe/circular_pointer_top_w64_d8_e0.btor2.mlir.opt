module attributes {llvm.data_layout = ""} {
  llvm.func @__VERIFIER_error()
  llvm.func @__SEA_assume(i1)
  llvm.func @nd_bv8_in7() -> i8
  llvm.func @nd_bv64_in6() -> i64
  llvm.func @nd_bv8_in5() -> i8
  llvm.func @nd_bv8_in2() -> i8
  llvm.func @nd_bv8_in4() -> i8
  llvm.func @nd_bv8_in3() -> i8
  llvm.func @btor2mlir_print_input_num(i64, i64, i64)
  llvm.func @nd_bv64_in1() -> i64
  llvm.func @nd_bv8_st16() -> i8
  llvm.func @nd_bv64_st14() -> i64
  llvm.func @nd_bv8_st13() -> i8
  llvm.func @nd_bv8_st12() -> i8
  llvm.func @nd_bv8_st11() -> i8
  llvm.func @nd_bv8_st10() -> i8
  llvm.func @nd_bv64_st9() -> i64
  llvm.func @nd_bv64_st8() -> i64
  llvm.func @nd_bv64_st7() -> i64
  llvm.func @nd_bv64_st6() -> i64
  llvm.func @nd_bv64_st5() -> i64
  llvm.func @nd_bv64_st4() -> i64
  llvm.func @nd_bv64_st3() -> i64
  llvm.func @nd_bv64_st2() -> i64
  llvm.func @nd_bv8_st1() -> i8
  llvm.func @btor2mlir_print_state_num(i64, i64, i64)
  llvm.func @nd_bv64_st0() -> i64
  llvm.func @main() {
    %0 = llvm.mlir.constant(true) : i1
    %1 = llvm.call @nd_bv64_st0() : () -> i64
    %2 = llvm.trunc %1 : i64 to i64
    %3 = llvm.call @nd_bv8_st1() : () -> i8
    %4 = llvm.trunc %3 : i8 to i5
    %5 = llvm.call @nd_bv64_st2() : () -> i64
    %6 = llvm.trunc %5 : i64 to i64
    %7 = llvm.call @nd_bv64_st3() : () -> i64
    %8 = llvm.trunc %7 : i64 to i64
    %9 = llvm.call @nd_bv64_st4() : () -> i64
    %10 = llvm.trunc %9 : i64 to i64
    %11 = llvm.call @nd_bv64_st5() : () -> i64
    %12 = llvm.trunc %11 : i64 to i64
    %13 = llvm.call @nd_bv64_st6() : () -> i64
    %14 = llvm.trunc %13 : i64 to i64
    %15 = llvm.call @nd_bv64_st7() : () -> i64
    %16 = llvm.trunc %15 : i64 to i64
    %17 = llvm.call @nd_bv64_st8() : () -> i64
    %18 = llvm.trunc %17 : i64 to i64
    %19 = llvm.call @nd_bv64_st9() : () -> i64
    %20 = llvm.trunc %19 : i64 to i64
    %21 = llvm.call @nd_bv8_st10() : () -> i8
    %22 = llvm.trunc %21 : i8 to i5
    %23 = llvm.call @nd_bv8_st11() : () -> i8
    %24 = llvm.trunc %23 : i8 to i1
    %25 = llvm.call @nd_bv8_st12() : () -> i8
    %26 = llvm.trunc %25 : i8 to i1
    %27 = llvm.call @nd_bv8_st13() : () -> i8
    %28 = llvm.trunc %27 : i8 to i5
    %29 = llvm.call @nd_bv64_st14() : () -> i64
    %30 = llvm.trunc %29 : i64 to i64
    %31 = llvm.call @nd_bv8_st16() : () -> i8
    %32 = llvm.trunc %31 : i8 to i5
    llvm.br ^bb1(%2, %4, %6, %8, %10, %12, %14, %16, %18, %20, %22, %24, %26, %28, %30, %0, %32 : i64, i5, i64, i64, i64, i64, i64, i64, i64, i64, i5, i1, i1, i5, i64, i1, i5)
  ^bb1(%33: i64, %34: i5, %35: i64, %36: i64, %37: i64, %38: i64, %39: i64, %40: i64, %41: i64, %42: i64, %43: i5, %44: i1, %45: i1, %46: i5, %47: i64, %48: i1, %49: i5):  // 2 preds: ^bb0, ^bb2
    %50 = llvm.call @nd_bv64_in1() : () -> i64
    %51 = llvm.trunc %50 : i64 to i64
    %52 = llvm.mlir.constant(-8 : i4) : i4
    %53 = llvm.mlir.constant(0 : i5) : i5
    %54 = llvm.lshr %49, %53  : i5
    %55 = llvm.trunc %54 : i5 to i4
    %56 = llvm.icmp "eq" %55, %52 : i4
    %57 = llvm.call @nd_bv8_in3() : () -> i8
    %58 = llvm.trunc %57 : i8 to i1
    %59 = llvm.and %58, %56  : i1
    %60 = llvm.select %59, %51, %33 : i1, i64
    %61 = llvm.mlir.constant(0 : i64) : i64
    %62 = llvm.call @nd_bv8_in4() : () -> i8
    %63 = llvm.trunc %62 : i8 to i1
    %64 = llvm.select %63, %61, %60 : i1, i64
    %65 = llvm.call @nd_bv8_in2() : () -> i8
    %66 = llvm.trunc %65 : i8 to i1
    %67 = llvm.zext %66 : i1 to i5
    %68 = llvm.add %34, %67  : i5
    %69 = llvm.or %58, %66  : i1
    %70 = llvm.or %69, %63  : i1
    %71 = llvm.select %70, %68, %34 : i1, i5
    %72 = llvm.mlir.constant(0 : i5) : i5
    %73 = llvm.select %63, %72, %71 : i1, i5
    %74 = llvm.mlir.constant(-1 : i3) : i3
    %75 = llvm.zext %74 : i3 to i4
    %76 = llvm.icmp "eq" %55, %75 : i4
    %77 = llvm.and %58, %76  : i1
    %78 = llvm.select %77, %51, %35 : i1, i64
    %79 = llvm.select %63, %61, %78 : i1, i64
    %80 = llvm.mlir.constant(-2 : i3) : i3
    %81 = llvm.zext %80 : i3 to i4
    %82 = llvm.icmp "eq" %55, %81 : i4
    %83 = llvm.and %58, %82  : i1
    %84 = llvm.select %83, %51, %36 : i1, i64
    %85 = llvm.select %63, %61, %84 : i1, i64
    %86 = llvm.mlir.constant(-3 : i3) : i3
    %87 = llvm.zext %86 : i3 to i4
    %88 = llvm.icmp "eq" %55, %87 : i4
    %89 = llvm.and %58, %88  : i1
    %90 = llvm.select %89, %51, %37 : i1, i64
    %91 = llvm.select %63, %61, %90 : i1, i64
    %92 = llvm.mlir.constant(-4 : i3) : i3
    %93 = llvm.zext %92 : i3 to i4
    %94 = llvm.icmp "eq" %55, %93 : i4
    %95 = llvm.and %58, %94  : i1
    %96 = llvm.select %95, %51, %38 : i1, i64
    %97 = llvm.select %63, %61, %96 : i1, i64
    %98 = llvm.mlir.constant(-1 : i2) : i2
    %99 = llvm.zext %98 : i2 to i4
    %100 = llvm.icmp "eq" %55, %99 : i4
    %101 = llvm.and %58, %100  : i1
    %102 = llvm.select %101, %51, %39 : i1, i64
    %103 = llvm.select %63, %61, %102 : i1, i64
    %104 = llvm.mlir.constant(-2 : i2) : i2
    %105 = llvm.zext %104 : i2 to i4
    %106 = llvm.icmp "eq" %55, %105 : i4
    %107 = llvm.and %58, %106  : i1
    %108 = llvm.select %107, %51, %40 : i1, i64
    %109 = llvm.select %63, %61, %108 : i1, i64
    %110 = llvm.mlir.constant(true) : i1
    %111 = llvm.zext %110 : i1 to i4
    %112 = llvm.icmp "eq" %55, %111 : i4
    %113 = llvm.and %58, %112  : i1
    %114 = llvm.select %113, %51, %41 : i1, i64
    %115 = llvm.select %63, %61, %114 : i1, i64
    %116 = llvm.bitcast %55 : i4 to vector<4xi1>
    %117 = "llvm.intr.vector.reduce.or"(%116) : (vector<4xi1>) -> i1
    %118 = llvm.mlir.constant(true) : i1
    %119 = llvm.xor %117, %118  : i1
    %120 = llvm.and %58, %119  : i1
    %121 = llvm.select %120, %51, %42 : i1, i64
    %122 = llvm.select %63, %61, %121 : i1, i64
    %123 = llvm.zext %66 : i1 to i5
    %124 = llvm.zext %58 : i1 to i5
    %125 = llvm.add %43, %124  : i5
    %126 = llvm.sub %125, %123  : i5
    %127 = llvm.select %63, %72, %126 : i1, i5
    %128 = llvm.call @nd_bv8_in5() : () -> i8
    %129 = llvm.trunc %128 : i8 to i1
    %130 = llvm.and %129, %58  : i1
    %131 = llvm.or %44, %130  : i1
    %132 = llvm.mlir.constant(true) : i1
    %133 = llvm.xor %44, %132  : i1
    %134 = llvm.select %133, %131, %44 : i1, i1
    %135 = llvm.mlir.constant(false) : i1
    %136 = llvm.select %63, %135, %134 : i1, i1
    %137 = llvm.zext %66 : i1 to i5
    %138 = llvm.mlir.constant(true) : i1
    %139 = llvm.xor %44, %138  : i1
    %140 = llvm.and %58, %139  : i1
    %141 = llvm.zext %140 : i1 to i5
    %142 = llvm.add %46, %141  : i5
    %143 = llvm.sub %142, %137  : i5
    %144 = llvm.select %63, %72, %143 : i1, i5
    %145 = llvm.bitcast %144 : i5 to vector<5xi1>
    %146 = "llvm.intr.vector.reduce.or"(%145) : (vector<5xi1>) -> i1
    %147 = llvm.mlir.constant(true) : i1
    %148 = llvm.xor %146, %147  : i1
    %149 = llvm.bitcast %46 : i5 to vector<5xi1>
    %150 = "llvm.intr.vector.reduce.or"(%149) : (vector<5xi1>) -> i1
    %151 = llvm.mlir.constant(true) : i1
    %152 = llvm.xor %45, %151  : i1
    %153 = llvm.and %44, %152  : i1
    %154 = llvm.and %153, %150  : i1
    %155 = llvm.and %154, %148  : i1
    %156 = llvm.or %155, %45  : i1
    %157 = llvm.select %110, %156, %45 : i1, i1
    %158 = llvm.select %63, %135, %157 : i1, i1
    %159 = llvm.or %58, %66  : i1
    %160 = llvm.or %159, %63  : i1
    %161 = llvm.or %160, %44  : i1
    %162 = llvm.select %161, %144, %46 : i1, i5
    %163 = llvm.select %63, %72, %162 : i1, i5
    %164 = llvm.and %130, %133  : i1
    %165 = llvm.select %164, %51, %47 : i1, i64
    %166 = llvm.select %63, %61, %165 : i1, i64
    %167 = llvm.zext %58 : i1 to i5
    %168 = llvm.add %49, %167  : i5
    %169 = llvm.select %70, %168, %49 : i1, i5
    %170 = llvm.select %63, %72, %169 : i1, i5
    %171 = llvm.mlir.constant(true) : i1
    %172 = llvm.xor %110, %171  : i1
    %173 = llvm.icmp "eq" %63, %48 : i1
    %174 = llvm.or %173, %172  : i1
    llvm.call @__SEA_assume(%174) : (i1) -> ()
    %175 = llvm.mlir.constant(true) : i1
    %176 = llvm.xor %110, %175  : i1
    %177 = llvm.mlir.constant(true) : i1
    %178 = llvm.xor %58, %177  : i1
    %179 = llvm.mlir.constant(-7 : i4) : i4
    %180 = llvm.zext %179 : i4 to i5
    %181 = llvm.icmp "eq" %43, %180 : i5
    %182 = llvm.mlir.constant(true) : i1
    %183 = llvm.xor %181, %182  : i1
    %184 = llvm.or %183, %178  : i1
    %185 = llvm.or %184, %176  : i1
    llvm.call @__SEA_assume(%185) : (i1) -> ()
    %186 = llvm.mlir.constant(true) : i1
    %187 = llvm.xor %110, %186  : i1
    %188 = llvm.mlir.constant(true) : i1
    %189 = llvm.xor %66, %188  : i1
    %190 = llvm.bitcast %43 : i5 to vector<5xi1>
    %191 = "llvm.intr.vector.reduce.or"(%190) : (vector<5xi1>) -> i1
    %192 = llvm.mlir.constant(true) : i1
    %193 = llvm.xor %191, %192  : i1
    %194 = llvm.mlir.constant(true) : i1
    %195 = llvm.xor %193, %194  : i1
    %196 = llvm.or %195, %189  : i1
    %197 = llvm.or %196, %187  : i1
    llvm.call @__SEA_assume(%197) : (i1) -> ()
    %198 = llvm.call @nd_bv64_in6() : () -> i64
    %199 = llvm.trunc %198 : i64 to i64
    %200 = llvm.mlir.constant(0 : i5) : i5
    %201 = llvm.lshr %34, %200  : i5
    %202 = llvm.trunc %201 : i5 to i4
    %203 = llvm.icmp "eq" %202, %52 : i4
    %204 = llvm.select %203, %33, %199 : i1, i64
    %205 = llvm.zext %74 : i3 to i4
    %206 = llvm.icmp "eq" %202, %205 : i4
    %207 = llvm.select %206, %35, %204 : i1, i64
    %208 = llvm.zext %80 : i3 to i4
    %209 = llvm.icmp "eq" %202, %208 : i4
    %210 = llvm.select %209, %36, %207 : i1, i64
    %211 = llvm.zext %86 : i3 to i4
    %212 = llvm.icmp "eq" %202, %211 : i4
    %213 = llvm.select %212, %37, %210 : i1, i64
    %214 = llvm.zext %92 : i3 to i4
    %215 = llvm.icmp "eq" %202, %214 : i4
    %216 = llvm.select %215, %38, %213 : i1, i64
    %217 = llvm.zext %98 : i2 to i4
    %218 = llvm.icmp "eq" %202, %217 : i4
    %219 = llvm.select %218, %39, %216 : i1, i64
    %220 = llvm.zext %104 : i2 to i4
    %221 = llvm.icmp "eq" %202, %220 : i4
    %222 = llvm.select %221, %40, %219 : i1, i64
    %223 = llvm.zext %110 : i1 to i4
    %224 = llvm.icmp "eq" %202, %223 : i4
    %225 = llvm.select %224, %41, %222 : i1, i64
    %226 = llvm.bitcast %202 : i4 to vector<4xi1>
    %227 = "llvm.intr.vector.reduce.or"(%226) : (vector<4xi1>) -> i1
    %228 = llvm.mlir.constant(true) : i1
    %229 = llvm.xor %227, %228  : i1
    %230 = llvm.select %229, %42, %225 : i1, i64
    %231 = llvm.icmp "eq" %47, %230 : i64
    %232 = llvm.mlir.constant(true) : i1
    %233 = llvm.xor %155, %232  : i1
    %234 = llvm.or %233, %231  : i1
    %235 = llvm.call @nd_bv8_in7() : () -> i8
    %236 = llvm.trunc %235 : i8 to i1
    %237 = llvm.select %48, %236, %234 : i1, i1
    %238 = llvm.mlir.constant(true) : i1
    %239 = llvm.xor %237, %238  : i1
    %240 = llvm.select %48, %135, %110 : i1, i1
    %241 = llvm.and %240, %239  : i1
    %242 = llvm.mlir.constant(true) : i1
    %243 = llvm.xor %241, %242  : i1
    llvm.cond_br %243, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    llvm.br ^bb1(%64, %73, %79, %85, %91, %97, %103, %109, %115, %122, %127, %136, %158, %163, %166, %135, %170 : i64, i5, i64, i64, i64, i64, i64, i64, i64, i64, i5, i1, i1, i5, i64, i1, i5)
  ^bb3:  // pred: ^bb1
    llvm.call @__VERIFIER_error() : () -> ()
    llvm.unreachable
  }
}

